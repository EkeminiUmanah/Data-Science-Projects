{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Dimensionalty Reduction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "-Machine Learning problems invlove thousands or even millions of features. \n",
    "\n",
    "-This makes the model really slow\n",
    "\n",
    "-Sometimes, it's harder' to find good solutions \n",
    "\n",
    "-Dimensionalty Reduction is a way to reduce these features into a few features without loosing information\n",
    "\n",
    "-Two Methods\n",
    "\n",
    "   Feature Selection\n",
    "    \n",
    "      1. Univariate Selection\n",
    "      2. Recursive Feature Elimination\n",
    "      3. Feature Importance\n",
    "      4. Forward Selection(Not in sklearn)\n",
    "      5. Backward Regression(Not in Sklearn)\n",
    "      6.LASSO Regression\n",
    "      7.Adaptive LASSO Regression\n",
    "   Feature Extraction\n",
    "    \n",
    "      1. Principal Component Analysis\n",
    "      2.Linear Discriminant Analysis\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection\n",
    "\n",
    "-Involves using statistical test to select features that have the strongest relationship with the output variable/target.\n",
    "\n",
    "-Sklearn has SelectKBest that can be used with  statistical tests to select features.\n",
    "\n",
    "-We use chisquare in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "[ 111.51969064 1411.88704064   17.60537322   53.10803984 2175.56527292\n",
      "  127.66934333    5.39268155  181.30368904]\n",
      "[[148.    0.   33.6  50. ]\n",
      " [ 85.    0.   26.6  31. ]\n",
      " [183.    0.   23.3  32. ]\n",
      " [ 89.   94.   28.1  21. ]\n",
      " [137.  168.   43.1  33. ]]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection using sklearn\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#filename='C:\\\\Users\\\\abiod\\\\Desktop\\\\R and D\\\\Data science\\\\data set\\\\pimas.csv'\n",
    "filename='/Users/aakogun/Desktop/Machine Learning/pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "# Feature Selection\n",
    "\n",
    "test= SelectKBest(score_func=chi2,k=4)\n",
    "\n",
    "#print(test)\n",
    "fit=test.fit(X,Y)\n",
    "\n",
    "print(fit.scores_)\n",
    "\n",
    "features=fit.transform(X)\n",
    "print(features[0:5,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-The highest scores are plas, test, mass, age\n",
    "\n",
    "-The features from the 4 chosen features are shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Extraction(RFE)\n",
    "\n",
    "-Works by Recursively removing atrributes and builds a models on the remaining atrributes\n",
    "\n",
    "-It uses the model accuracy to identify which atrributes ( and combination of atrributes) contributes the most to predicting the target value.\n",
    "\n",
    "-The example below use Logistic Regression and RFE to select top 3 features(preg,mass,pedi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Number of features :  3\n",
      "Selected Features [ True False False False False  True  True False]\n",
      "Ranking of Features [1 2 4 5 6 1 1 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/advancedanalytics/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# RFE\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='/Users/aakogun/Desktop/Machine Learning/pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "rfe=RFE(model,3)\n",
    "\n",
    "fit=rfe.fit(X,Y)\n",
    "\n",
    "print(\"Number of features : \",fit.n_features_)\n",
    "\n",
    "print(\"Selected Features\", fit.support_)\n",
    "\n",
    "print(\"Ranking of Features\", fit.ranking_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "-Bagged Decison Trees like Random Forest and Extra Trees can be used to estimate the importance of features\n",
    "\n",
    "-Example below using Extra Classifier and Random Forest has Plas, age and mass as the 3 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Model Importance using Extra Classifier [0.11068086 0.23848714 0.09716407 0.08036948 0.07223759 0.14424283\n",
      " 0.11880775 0.13801028]\n",
      "Model Importance using Random Forest [0.08404599 0.26720792 0.08769589 0.06653064 0.06939441 0.15778474\n",
      " 0.13130304 0.13603738]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='/Users/aakogun/Desktop/Machine Learning/pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance with Extra Tree Classifier\n",
    "\n",
    "print(\"Model Importance using Extra Classifier\",model.feature_importances_)\n",
    "\n",
    "\n",
    "#Feature Importance with Random Forest Classifier\n",
    "\n",
    "\n",
    "model2=RandomForestClassifier()\n",
    "model2.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance\n",
    "\n",
    "print(\"Model Importance using Random Forest\",model2.feature_importances_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "-Most Popular dimenstionalty reduction algorithm\n",
    "\n",
    "-Suppose you are interested in using linear models to determine relationship between a set of features/predictors and a response variable\n",
    "\n",
    "-If there is collinearity amongst your predictor variables\n",
    "\n",
    "-Collinearity amongst your variables might cause unstable models\n",
    "\n",
    "-PCA is a variable reduction strategy\n",
    "\n",
    "-In PCA, we create a weighted linear combinations of variables while retaining most of the variability in the data\n",
    "\n",
    "-Lead to fewer variables with little or no lost information\n",
    "\n",
    "-PCA retains most of the information in a high dimenstion data by transforming the data\n",
    "\n",
    "-Most of the variability in the origianl data can be retained.\n",
    "\n",
    "-Components might not be directly interpretable.\n",
    "\n",
    "-Resulting component scores can be used as input to subsequent analysis\n",
    "\n",
    "-New variables are un-correlated\n",
    "\n",
    "-Performs Eigen value decomposition of the correlation or covariance matrix\n",
    "\n",
    "-It creates components that consolidate more of the explained variance into the first few PCs.\n",
    "\n",
    "-PCs are mutually orthogonal and independent\n",
    "\n",
    "-Generated so that the first PCs accounts for most of the variation in the data followed by the second PC and so on.\n",
    "\n",
    "\n",
    "-Principal components provides least square estimates of the form Y=XB\n",
    "\n",
    "-Y is n by p component of scores\n",
    "\n",
    "-X is n by j matrix of observed variables\n",
    "\n",
    "-B is j by p matrix of eigen vectors of the correlation or covariance matrix of variables\n",
    "\n",
    "-A scree plot of eigen values can be used to decide how many components to retain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Explained Variance ratio [0.26179749 0.21640127 0.12870373 0.10944113 0.09529305]\n",
      "Explained variance/Eigenvalues [2.09711056 1.73346726 1.03097228 0.87667054 0.76333832]\n",
      "Components/eigen vectors [[ 0.1284321   0.39308257  0.36000261  0.43982428  0.43502617  0.45194134\n",
      "   0.27061144  0.19802707]\n",
      " [ 0.59378583  0.17402908  0.18389207 -0.33196534 -0.25078106 -0.1009598\n",
      "  -0.122069    0.62058853]\n",
      " [-0.01308692  0.46792282 -0.53549442 -0.2376738   0.33670893 -0.36186463\n",
      "   0.43318905  0.07524755]\n",
      " [ 0.08069115 -0.40432871  0.05598649  0.03797608 -0.34994376  0.05364595\n",
      "   0.8336801   0.0712006 ]\n",
      " [-0.47560573  0.46632804  0.32795306 -0.48786206 -0.34693481  0.25320376\n",
      "   0.11981049 -0.10928996]]\n",
      "[26.18 47.82 60.69 71.63 81.16]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='/Users/aakogun/Desktop/Machine Learning/pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "X=scale(X)\n",
    "\n",
    "pca=PCA(n_components=.8)\n",
    "#pca=PCA(n_components=3)\n",
    "fit=pca.fit(X)\n",
    "\n",
    "print(\"Explained Variance ratio\",fit.explained_variance_ratio_)\n",
    "print(\"Explained variance/Eigenvalues\",pca.explained_variance_)\n",
    "print(\"Components/eigen vectors\",pca.components_)\n",
    "\n",
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print(var)\n",
    "\n",
    "plt.plot(var)\n",
    "\n",
    "plt.show()\n",
    "#print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0   8.3252        41  6.984127   1.023810         322  2.555556     37.88   \n",
      "1   8.3014        21  6.238137   0.971880        2401  2.109842     37.86   \n",
      "2   7.2574        52  8.288136   1.073446         496  2.802260     37.85   \n",
      "3   5.6431        52  5.817352   1.073059         558  2.547945     37.85   \n",
      "4   3.8462        52  6.281853   1.081081         565  2.181467     37.85   \n",
      "5   4.0368        52  4.761658   1.103627         413  2.139896     37.85   \n",
      "6   3.6591        52  4.931907   0.951362        1094  2.128405     37.84   \n",
      "7   3.1200        52  4.797527   1.061824        1157  1.788253     37.84   \n",
      "8   2.0804        42  4.294118   1.117647        1206  2.026891     37.84   \n",
      "9   3.6912        52  4.970588   0.990196        1551  2.172269     37.84   \n",
      "10  3.2031        52  5.477612   1.079602         910  2.263682     37.85   \n",
      "11  3.2705        52  4.772480   1.024523        1504  2.049046     37.85   \n",
      "12  3.0750        52  5.322650   1.012821        1098  2.346154     37.85   \n",
      "13  2.6736        52  4.000000   1.097701         345  1.982759     37.84   \n",
      "14  1.9167        52  4.262903   1.009677        1212  1.954839     37.85   \n",
      "15  2.1250        50  4.242424   1.071970         697  2.640152     37.85   \n",
      "16  2.7750        52  5.939577   1.048338         793  2.395770     37.85   \n",
      "17  2.1202        52  4.052805   0.966997         648  2.138614     37.85   \n",
      "18  1.9911        50  5.343675   1.085919         990  2.362768     37.84   \n",
      "19  2.6033        52  5.465455   1.083636         690  2.509091     37.84   \n",
      "\n",
      "    Longitude  MEDIAN VALUE  \n",
      "0     -122.23         4.526  \n",
      "1     -122.22         3.585  \n",
      "2     -122.24         3.521  \n",
      "3     -122.25         3.413  \n",
      "4     -122.25         3.422  \n",
      "5     -122.25         2.697  \n",
      "6     -122.25         2.992  \n",
      "7     -122.25         2.414  \n",
      "8     -122.26         2.267  \n",
      "9     -122.25         2.611  \n",
      "10    -122.26         2.815  \n",
      "11    -122.26         2.418  \n",
      "12    -122.26         2.135  \n",
      "13    -122.26         1.913  \n",
      "14    -122.26         1.592  \n",
      "15    -122.26         1.400  \n",
      "16    -122.27         1.525  \n",
      "17    -122.27         1.555  \n",
      "18    -122.26         1.587  \n",
      "19    -122.27         1.629  \n",
      "(20640, 9)\n",
      "Model Importance using Extra Regressor [0.49681218 0.07153728 0.04302066 0.03410856 0.02760675 0.10660939\n",
      " 0.10696154 0.11334365]\n",
      "Model Importance using Random Regressor [0.51819102 0.05356825 0.0435451  0.02924369 0.03094312 0.13708456\n",
      " 0.09467866 0.09274561]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection using sklearn\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#C:\\Users\\abiod\\Desktop\\R and D\\Data science\\data set\n",
    "#names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv('/Users/aakogun/Desktop/Machine Learning/california.csv')\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "model=ExtraTreesRegressor()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance with Extra Tree Classifier\n",
    "\n",
    "print(\"Model Importance using Extra Regressor\",model.feature_importances_)\n",
    "\n",
    "\n",
    "#Feature Importance with Random Forest Classifier\n",
    "\n",
    "\n",
    "model2=RandomForestRegressor()\n",
    "model2.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance\n",
    "\n",
    "print(\"Model Importance using Random Regressor\",model2.feature_importances_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
